[
  {
    "objectID": "notebook/2_1_modsculpt_compas.html",
    "href": "notebook/2_1_modsculpt_compas.html",
    "title": "2.1. Model sculpting and interpretation - compas",
    "section": "",
    "text": "The following scripts need to be run first before knitting the document corresponding to model_type specified below:\n\n3_model_sculpt_compas.R\nSculpting - Main models chunk (need to manually run in the interactive mode, not run during knitting as it takes some time)",
    "crumbs": [
      "Notebook",
      "2.1. Model sculpting and interpretation - compas"
    ]
  },
  {
    "objectID": "notebook/2_1_modsculpt_compas.html#sculpting",
    "href": "notebook/2_1_modsculpt_compas.html#sculpting",
    "title": "2.1. Model sculpting and interpretation - compas",
    "section": "Sculpting",
    "text": "Sculpting\n\nMain models\nSculpting on product marginals on logit scale.\n\n\nShow the code\n# # get rough model - on pm\n# # Already generated in 3_model_sculpt_compas.R\n# rs_pm &lt;- sculpt_rough(\n#   pm,\n#   seed = 1234,\n#   model_predict_fun = function(x) {\n#     p &lt;- predict(xgb, new_data = x, type = \"prob\")$.pred_1\n#     logit(p)\n#   }\n# )\n\n\n# # detailed model on pm\n# Already generated in 3_model_sculpt_compas.R\n# ds_pm &lt;- sculpt_detailed_gam(rs_pm)\n\n## Below we use custom smoother for even better fitting smoothings\ngam_cgam_smoother &lt;- function(x, y, is_discrete, column_name, na_ind = NULL) {\n  use_cgam &lt;- TRUE\n  if (column_name == \"age\") {\n    s.decr &lt;- cgam::s.decr\n    form &lt;- y ~ s.decr(x, numknots = 3)\n  } else if (column_name == \"priors\") {\n    s.incr &lt;- cgam::s.incr\n    form &lt;- y ~ s.incr(x, numknots = 3)\n  } else if (column_name == \"juvenile_crimes\") {\n    return(getPAVAest(outcome = y, score = x)) # from stats4phc\n  } else {\n    use_cgam &lt;- FALSE\n  }\n  if (use_cgam) {\n    tryCatch(\n      cgam::cgam(form), \n      error = function(e) {\n        s &lt;- mgcv::s\n        tryCatch(\n          mgcv::gam(y ~ s(x, k = -1)),\n          error = function(e) {\n            mgcv::gam(y ~ x)\n          }\n        )\n      }\n    )\n  } else {\n    if (is_discrete) {\n      s &lt;- mgcv::s\n      tryCatch(\n        mgcv::gam(y ~ x),\n        error = function(e) {\n          lm(y ~ 0)\n        }\n      )\n    } else {\n      s &lt;- mgcv::s\n      tryCatch(\n        mgcv::gam(y ~ s(x, k = -1)),\n        error = function(e) {\n          mgcv::gam(y ~ x)\n        }\n      )\n    }\n  }\n}\n\ngam_cgam_predict &lt;- function(smoother, new_x, is_discrete, column_name, na_ind = NULL) {\n  if (inherits(smoother, \"cgam\")) {\n    # cgam fails on extrapolation - need to do this manually\n    if (min(new_x) &lt; min(smoother$xmat0[, 1])) {\n      new_x[new_x &lt; min(smoother$xmat0[, 1])] &lt;- min(smoother$xmat0[, 1])\n    }\n    if (max(new_x) &gt; max(smoother$xmat0[, 1])) {\n      new_x[new_x &gt; max(smoother$xmat0[, 1])] &lt;- max(smoother$xmat0[, 1])\n    }\n    newdata &lt;- data.frame(x = new_x)\n    predict(smoother, newData = newdata)$fit\n  } else if (inherits(smoother, \"gam\")) {\n    newdata &lt;- data.frame(x = new_x)\n    as.numeric(predict(smoother, newdata = newdata))\n  } else if (is.data.frame(smoother)) {\n    # specific for pava as there is no model returned, just a vector\n    ifelse(\n      new_x == 0, \n      smoother$estimate[smoother$score == 0][1],\n      ifelse(\n        new_x == 1, \n        smoother$estimate[smoother$score == 1][1],\n        smoother$estimate[smoother$score == 2][1]\n      )\n    )\n  }\n}\n\n\npolished_smoother &lt;- function(x, y, is_discrete, column_name, na_ind = NULL) {\n  if (column_name == \"age\") {\n    s.decr &lt;- cgam::s.decr\n    form &lt;- y ~ s.decr(x, numknots = 3)\n  } else if (column_name == \"priors\") {\n    s.incr &lt;- cgam::s.incr\n    form &lt;- y ~ s.incr(x, numknots = 3)\n  } else if (column_name == \"juvenile_crimes\") {\n    return(getPAVAest(outcome = y, score = x)) # from stats4phc\n  } else {\n    out &lt;- list()\n    class(out) &lt;- \"constant\"\n    return(out)\n  }\n  tryCatch(\n    cgam::cgam(form), \n    error = function(e) {\n      s &lt;- mgcv::s\n      tryCatch(\n        mgcv::gam(y ~ s(x, k = -1)),\n        error = function(e) {\n          mgcv::gam(y ~ x)\n        }\n      )\n    }\n  )\n}\n\npolished_smoother_predict &lt;- function(smoother, new_x, is_discrete, column_name, na_ind = NULL) {\n  if (inherits(smoother, \"cgam\")) {\n    # cgam fails on extrapolation - need to do this manually\n    if (min(new_x) &lt; min(smoother$xmat0[, 1])) {\n      new_x[new_x &lt; min(smoother$xmat0[, 1])] &lt;- min(smoother$xmat0[, 1])\n    }\n    if (max(new_x) &gt; max(smoother$xmat0[, 1])) {\n      new_x[new_x &gt; max(smoother$xmat0[, 1])] &lt;- max(smoother$xmat0[, 1])\n    }\n    newdata &lt;- data.frame(x = new_x)\n    predict(smoother, newData = newdata)$fit\n  } else if (inherits(smoother, \"constant\")) { \n    0\n  } else if (is.data.frame(smoother)) {\n    # specific for pava as there is no model returned, just a vector\n    ifelse(\n      new_x == 0, \n      smoother$estimate[smoother$score == 0][1],\n      ifelse(\n        new_x == 1, \n        smoother$estimate[smoother$score == 1][1],\n        smoother$estimate[smoother$score == 2][1]\n      )\n    )\n  }\n}\n\nrs_pm &lt;- load_results(paste0(dataset, \"-\", model_type, \"-sculpt_rough_pm.rds\"))\n\nds_pm_v2 &lt;- sculpt_detailed_generic(\n  rs = rs_pm,\n  smoother_fit = gam_cgam_smoother, \n  smoother_predict = gam_cgam_predict\n)\n\n# Select variables for polished model\ncheckmate::assert_number(top_k, lower = 1)\nvars &lt;- levels(attr(rs_pm, \"cumul_R2\")$feature)[1:top_k]\n\nrs_pm_top_k &lt;- rs_pm[vars]\nattr(rs_pm_top_k, \"offset\") &lt;- attr(rs_pm, \"offset\")\nclass(rs_pm_top_k) &lt;- class(rs_pm)\n\nps_pm_v2 &lt;- sculpt_detailed_generic(\n  rs = rs_pm_top_k,\n  smoother_fit = polished_smoother, \n  smoother_predict = polished_smoother_predict\n)\n\nstore_results(ds_pm_v2, paste0(dataset, \"-\", model_type, \"-sculpt_detailed_pm_v2.rds\"))\nstore_results(ps_pm_v2, paste0(dataset, \"-\", model_type, \"-sculpt_polished_pm_v2.rds\"))\n\n\n\n\nShow the code\n# load sculpted models\nrs_pm &lt;- load_results(paste0(dataset, \"-\", model_type, \"-sculpt_rough_pm.rds\"))\nds_pm &lt;- load_results(paste0(dataset, \"-\", model_type, \"-sculpt_detailed_pm.rds\"))\nps_pm &lt;- load_results(paste0(dataset, \"-\", model_type, \"-sculpt_polished_pm.rds\"))\nds_pm_v2 &lt;- load_results(paste0(dataset, \"-\", model_type, \"-sculpt_detailed_pm_v2.rds\"))\nps_pm_v2 &lt;- load_results(paste0(dataset, \"-\", model_type, \"-sculpt_polished_pm_v2.rds\"))\n\n\n\n\nOther sculpting models\n\n\nShow the code\n# get rough model - on train\nrs_train &lt;- sculpt_rough(\n  dd$data$train[dd$covariates$all],\n  seed = 1234,\n  model_predict_fun = function(x) {\n    p &lt;- predict(xgb, new_data = x, type = \"prob\")$.pred_1\n    logit(p)\n  },\n  data_as_marginals = TRUE\n)\n\n# rough model on pm on original scale\nrs_pm_prob &lt;- sculpt_rough(\n  pm,\n  seed = 1234,\n  model_predict_fun = function(x) {\n    predict(xgb, new_data = x, type = \"prob\")$.pred_1\n  }\n)\n\n# rough model on train on original scale\nrs_train_prob &lt;- sculpt_rough(\n  dd$data$train[dd$covariates$all],\n  seed = 1234,\n  model_predict_fun = function(x) {\n    predict(xgb, new_data = x, type = \"prob\")$.pred_1\n  },\n  data_as_marginals = TRUE\n)\n\n# First order model\nrs_pm_xgb_fo &lt;- sculpt_rough(\n  pm, \n  seed = 1234,\n  model_predict_fun = function(x) {\n    p &lt;- predict(xgb_fo, new_data = x, type = \"prob\")$.pred_1\n    logit(p)\n  }\n)",
    "crumbs": [
      "Notebook",
      "2.1. Model sculpting and interpretation - compas"
    ]
  },
  {
    "objectID": "notebook/2_1_modsculpt_compas.html#ice-plots",
    "href": "notebook/2_1_modsculpt_compas.html#ice-plots",
    "title": "2.1. Model sculpting and interpretation - compas",
    "section": "ICE plots",
    "text": "ICE plots\n\n\nShow the code\nscale_col_update &lt;- \n  scale_color_manual(\n    values = c(\"ICE Profiles\" = \"gray60\", \"Rough model (with SE)\" = \"blue\"),\n    labels = c(\"ICE Profiles\", \"Rough model\"),\n    name = \"\"\n  )\n\nice_pm_ceteris &lt;- g_ice(rs_pm, centered = F, show_PDP = F, \n                        facet_spec = facet_specification(ncol = 3))\nice_pm_ceteris_prob &lt;- g_ice(rs_pm_prob, centered = F, show_PDP = F, \n                             facet_spec = facet_specification(ncol = 3))\nice_pm &lt;- g_ice(rs_pm, centered = T, show_PDP = T, \n                facet_spec = facet_specification(ncol = 3))\n\n\n\nRough: Logit scaleRough: Prob. scaleRough: Logit, centeredRough vs direct 1st orderDetailed vs roughPolished vs rough\n\n\n\n\nShow the code\nice_pm_ceteris$continuous + theme_facets\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nice_pm_ceteris$discrete\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nice_pm_ceteris_prob$continuous + theme_facets\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nice_pm_ceteris_prob$discrete\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nice_pm$continuous + scale_col_update + theme_facets\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nice_pm$discrete + scale_col_update\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# comparison plot\ncomp_xgb_bayes &lt;- g_comparison(\n  sculptures = list(rs_pm, rs_pm_xgb_fo),\n  descriptions = c(\"Rough Model\", \"Direct Additive XGB\"), \n  facet_spec = facet_specification(ncol = 3)\n)\n\ncomp_xgb_bayes$continuous + theme_facets\n\n\n\n\n\n\n\n\n\n\n\nShow the code\ncomp_xgb_bayes$discrete\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# compare detailed and rough\ncomp_ds &lt;- \n  g_comparison(\n    sculptures = list(rs_pm, ds_pm_v2),\n    descriptions = c(\"Rough Model\", \"Detailed Model\"), \n    facet_spec = facet_specification(ncol = 3)\n  )\n\ncomp_ds$continuous + theme_facets\n\n\n\n\n\n\n\n\n\n\n\nShow the code\ncomp_ds$discrete\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# compare detailed and rough\n## Select variables for polished model\ncheckmate::assert_number(top_k, lower = 1)\nvars &lt;- levels(attr(rs_pm, \"cumul_R2\")$feature)[1:top_k]\n\nrs_pm_top_k &lt;- rs_pm[vars]\nattr(rs_pm_top_k, \"offset\") &lt;- attr(rs_pm, \"offset\")\nclass(rs_pm_top_k) &lt;- class(rs_pm)\n\ncomp_ps &lt;- \n  g_comparison(\n    sculptures = list(rs_pm_top_k, ps_pm_v2),\n    descriptions = c(\"Rough Model\", \"Polished Model\"), \n    facet_spec = facet_specification(ncol = 3)\n  )\n\ncomp_ps$continuous + theme_facets",
    "crumbs": [
      "Notebook",
      "2.1. Model sculpting and interpretation - compas"
    ]
  },
  {
    "objectID": "notebook/2_1_modsculpt_compas.html#data-density",
    "href": "notebook/2_1_modsculpt_compas.html#data-density",
    "title": "2.1. Model sculpting and interpretation - compas",
    "section": "Data density",
    "text": "Data density\n\n\nShow the code\ng_density_plots_cont &lt;- g_density_ice_plot_list(ps_pm_v2,\n                                                dd$data$train,\n                                                var_names = dd$covariates$continuous,\n                                                var_labels = dd$covariates$labels,\n                                                task = dd$task)\n# patchwork::wrap_plots(g_density_plots_cont[c(\"priors\", \"age\", \"juvenile_crimes\")], ncol = 2) \n\n\n\npriorsagejuvenile_crimes\n\n\n\n\nShow the code\ng_density_plots_cont[[\"priors\"]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\ng_density_plots_cont[[\"age\"]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\ng_density_plots_cont[[\"juvenile_crimes\"]]",
    "crumbs": [
      "Notebook",
      "2.1. Model sculpting and interpretation - compas"
    ]
  },
  {
    "objectID": "notebook/2_1_modsculpt_compas.html#additivity-evaluation",
    "href": "notebook/2_1_modsculpt_compas.html#additivity-evaluation",
    "title": "2.1. Model sculpting and interpretation - compas",
    "section": "Additivity evaluation",
    "text": "Additivity evaluation\n\n\nShow the code\np1 &lt;- predict(xgb, new_data = pm, type = \"prob\")$.pred_1\np2 &lt;- predict(xgb, new_data = dd$data$train, type = \"prob\")$.pred_1\np3 &lt;- predict(rs_pm, pm)\np4 &lt;- predict(rs_train, dd$data$train)\n\ng_additivity(\n  sp = list(inv.logit(p3), inv.logit(p4)),\n  lp = list(p1, p2),\n  descriptions = c(\"Product Marginals\", \"Train Set\")\n) + \n    labs(x = \"Rough Model Predictions\", y = \"Strong Learner Predictions\") + \n    theme_single",
    "crumbs": [
      "Notebook",
      "2.1. Model sculpting and interpretation - compas"
    ]
  },
  {
    "objectID": "notebook/2_1_modsculpt_compas.html#variable-importance",
    "href": "notebook/2_1_modsculpt_compas.html#variable-importance",
    "title": "2.1. Model sculpting and interpretation - compas",
    "section": "Variable importance",
    "text": "Variable importance\n\nLogit scale, pmProb scale, pmLogit scale, trainProb scale, train\n\n\n\n\nShow the code\nvi_pm &lt;- g_var_imp(rs_pm, show_pdp_plot = FALSE, textsize = 16, var_imp_type = \"ice\", \n                   logodds_to_prob = F)\nplot(vi_pm)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nvi_pm_prob &lt;- g_var_imp(rs_pm, show_pdp_plot = FALSE, textsize = 16, var_imp_type = \"ice\", \n                        logodds_to_prob = T)\nplot(vi_pm_prob)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nvi_train &lt;- g_var_imp(rs_train, show_pdp_plot = FALSE, textsize = 16, var_imp_type = \"ice\", \n                      logodds_to_prob = F)\nplot(vi_train)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nvi_train_prob &lt;- g_var_imp(rs_train, show_pdp_plot = FALSE, textsize = 16, var_imp_type = \"ice\", \n                           logodds_to_prob = T)\nplot(vi_train_prob)",
    "crumbs": [
      "Notebook",
      "2.1. Model sculpting and interpretation - compas"
    ]
  },
  {
    "objectID": "notebook/2_1_modsculpt_compas.html#calibration",
    "href": "notebook/2_1_modsculpt_compas.html#calibration",
    "title": "2.1. Model sculpting and interpretation - compas",
    "section": "Calibration",
    "text": "Calibration\n\n\nShow the code\npreds_sculptures &lt;- tibble(\n  obs = as.numeric(as.character(dd$data$holdout[[dd$response]])),\n  obs_fct = factor(dd$data$holdout[[dd$response]], levels = c(\"0\", \"1\")),\n  xgb_prob = predict(xgb, new_data = dd$data$holdout, type = \"prob\")$.pred_1,\n  rm_log = predict(rs_pm, newdata = dd$data$holdout),\n  pm_log = predict(ps_pm_v2, newdata = dd$data$holdout),\n  dir_prob = predict(xgb_fo, new_data = dd$data$holdout, type = \"prob\")$.pred_1\n) %&gt;%\n  mutate(\n    rm_prob = inv.logit(rm_log),\n    pm_prob = inv.logit(pm_log)\n  ) %&gt;%\n  pivot_longer(\n    cols = -c(obs, obs_fct),\n    names_to = c(\"Model\", \"type\"), names_sep = \"_\",\n    values_to = \"pred\"\n  ) %&gt;%\n  filter(type == \"prob\") %&gt;% \n  mutate(\n    Model = c(\n      \"xgb\" = \"XGBoost\", \"rm\" = \"Rough Model\",\n      \"pm\" = \"Polished Model\", \"dir\" = \"Direct Additive XGBoost\"\n    )[Model],\n    Model = factor(\n      Model, \n      levels = c(\n        \"XGBoost\", \"Rough Model\", \"Polished Model\", \"Direct Additive XGBoost\"\n      )\n    )\n  )\n\ncalib_plot_sculptures &lt;- ggplot(preds_sculptures) + \n  geom_smooth(aes(x = pred, y = obs, colour = Model), se = F, method = \"gam\", formula = y~x, \n              method.args = list(family = \"binomial\")) + \n  geom_abline(linetype = \"dashed\") + \n  labs(x = \"Prediction\", y = \"Truth\") + \n  theme_bw() + \n  theme(text = element_text(size = 18))\n\ncalib_plot_sculptures",
    "crumbs": [
      "Notebook",
      "2.1. Model sculpting and interpretation - compas"
    ]
  },
  {
    "objectID": "notebook/2_1_modsculpt_compas.html#predictiveness-curve",
    "href": "notebook/2_1_modsculpt_compas.html#predictiveness-curve",
    "title": "2.1. Model sculpting and interpretation - compas",
    "section": "Predictiveness curve",
    "text": "Predictiveness curve\nThe plot was generated using the riskProfile function from the stats4phc package.\n\n\nShow the code\nrp &lt;- riskProfile(\n  outcome = as.numeric(as.character(dd$data$holdout[[dd$response]])),\n  score = inv.logit(predict(ps_pm_v2, dd$data$holdout)),\n  show.nonparam.pv = FALSE,\n  show.best.pv = FALSE\n)\n\ndm_corel &lt;- define_model(\"corel_publication\", dd)\npreds_corel &lt;- predict(dm_corel$workflow, new_data = dd$data$holdout)$.pred_class\npreds_corel_fct &lt;- factor(preds_corel, levels = c(\"1\", \"0\"))\n\ndat_corel &lt;- tibble(\n  score_percentile = 1 - mean(preds_corel),\n  PPV = ppv_vec(\n    truth = dd$data$holdout[[dd$response]], \n    estimate = preds_corel_fct, \n    event_level = \"first\"\n  ),\n  `1-NPV` = 1 - npv_vec(\n    truth = dd$data$holdout[[dd$response]], \n    estimate = preds_corel_fct, \n    event_level = \"first\"\n  )\n) %&gt;% pivot_longer(cols = c(PPV, `1-NPV`))\n\n# final Predictiveness curve with corel alg.\npc_plot &lt;- \n  rp$plot + \n  geom_point(\n    data = dat_corel,\n    mapping = aes(x = score_percentile, y = value, colour = name),\n    size = 3\n  )\n\n\nplot(pc_plot)\n\n\n\n\n\n\n\n\n\nShow the code\n# Below are to generate separate legends for slides\n# plot(rp$plot + labs(color = \"Predictive Quantity\\n(Polished model)\"))\n# clrs &lt;- stats4phc:::predictionColours(c(\"PC\", \"PPV\", \"1-NPV\"), show.best = FALSE)\n# p &lt;- p + scale_colour_manual(values = clrs, breaks = names(clrs))\n# ggplot(dat_corel, aes(x = score_percentile, y = value, colour = name)) + \n#   geom_point(size = 3) + \n#   scale_colour_manual(values = clrs, breaks = names(clrs)) + \n#   labs(color = \"Predictive Quantity\\n(CORELS)\")",
    "crumbs": [
      "Notebook",
      "2.1. Model sculpting and interpretation - compas"
    ]
  },
  {
    "objectID": "notebook/2_1_modsculpt_compas.html#load-and-sculpt",
    "href": "notebook/2_1_modsculpt_compas.html#load-and-sculpt",
    "title": "2.1. Model sculpting and interpretation - compas",
    "section": "Load and sculpt",
    "text": "Load and sculpt\n\n\nShow the code\nelastic &lt;- load_model_if_trained(\"log_elastic\")\nlasso &lt;- load_model_if_trained(\"log_lasso\")\nridge &lt;- load_model_if_trained(\"log_ridge\")\n\ndm_linm &lt;- define_model(type = \"logistic\", data_info = dd)\nlinm &lt;- fit(dm_linm$workflow, data = dd$data$train)\ntg_linm &lt;- fit_resamples(dm_linm$workflow, dd$cv)\n\n\n\n\nShow the code\n# sculptures on pm from different models\nrs_pm_elastic &lt;- sculpt_rough(\n  pm,\n  seed = 1234,\n  model_predict_fun = function(x) {\n    p &lt;- predict(elastic, new_data = x, type = \"prob\")$.pred_1\n    logit(p)\n  }\n)\nrs_pm_lasso &lt;- sculpt_rough(\n  pm,\n  seed = 1234,\n  model_predict_fun = function(x) {\n    p &lt;- predict(lasso, new_data = x, type = \"prob\")$.pred_1\n    logit(p)\n  }\n)\nrs_pm_ridge &lt;- sculpt_rough(\n  pm,\n  seed = 1234,\n  model_predict_fun = function(x) {\n    p &lt;- predict(ridge, new_data = x, type = \"prob\")$.pred_1\n    logit(p)\n  }\n)\nrs_pm_linm &lt;- sculpt_rough(\n  pm,\n  seed = 1234,\n  model_predict_fun = function(x) {\n    p &lt;- predict(linm, new_data = x, type = \"prob\")$.pred_1\n    logit(p)\n  }\n)",
    "crumbs": [
      "Notebook",
      "2.1. Model sculpting and interpretation - compas"
    ]
  },
  {
    "objectID": "notebook/2_1_modsculpt_compas.html#ice",
    "href": "notebook/2_1_modsculpt_compas.html#ice",
    "title": "2.1. Model sculpting and interpretation - compas",
    "section": "ICE",
    "text": "ICE\n\n\nShow the code\ncomp_models &lt;- g_comparison(\n  sculptures = list(rs_pm_elastic, rs_pm_lasso, rs_pm_ridge, rs_pm_linm, ps_pm_v2),\n  descriptions = c(\"Elastic Net\", \"Lasso\", \"Ridge\", \"Logistic Regression\", \"Polished\"),\n  facet_spec = facet_specification(ncol = 3)\n)\n\ncomp_models$continuous + theme_facets\n\n\n\n\n\n\n\n\n\nShow the code\ncomp_models$discrete",
    "crumbs": [
      "Notebook",
      "2.1. Model sculpting and interpretation - compas"
    ]
  },
  {
    "objectID": "notebook/2_1_modsculpt_compas.html#calibration-1",
    "href": "notebook/2_1_modsculpt_compas.html#calibration-1",
    "title": "2.1. Model sculpting and interpretation - compas",
    "section": "Calibration",
    "text": "Calibration\n\n\nShow the code\npreds_models &lt;- tibble(\n  obs = as.numeric(as.character(dd$data$holdout[[dd$response]])),\n  obs_fct = factor(dd$data$holdout[[dd$response]], levels = c(\"0\", \"1\")),\n  xgbPol_log = predict(ps_pm_v2, newdata = dd$data$holdout),\n  linm_log = predict(rs_pm_linm, newdata = dd$data$holdout),\n  elastic_log = predict(rs_pm_elastic, newdata = dd$data$holdout),\n  lasso_log = predict(rs_pm_lasso, newdata = dd$data$holdout),\n  ridge_log = predict(rs_pm_ridge, newdata = dd$data$holdout)\n) %&gt;% \n  mutate(\n    xgbPol_prob = inv.logit(xgbPol_log),\n    linm_prob = inv.logit(linm_log),\n    elastic_prob = inv.logit(elastic_log),\n    lasso_prob = inv.logit(lasso_log),\n    ridge_prob = inv.logit(ridge_log)\n  ) %&gt;%\n  pivot_longer(\n    cols = -c(obs, obs_fct),\n    names_to = c(\"Model\", \"type\"), names_sep = \"_\",\n    values_to = \"pred\"\n  ) %&gt;%\n  filter(type == \"prob\") %&gt;% \n  mutate(\n    Model = c(\n      \"xgbPol\" = \"Polished\", \n      \"linm\" = \"Logistic\", \"elastic\" = \"Elastic Net\", \"lasso\" = \"Lasso\", \"ridge\" = \"Ridge\" \n    )[Model]\n  )\n\n# calibration plot on holdout based on pm sculptures of different linear models\ncalib_plot_models &lt;- ggplot(preds_models) + \n  geom_smooth(aes(x = pred, y = obs, colour = Model), se = F, method = \"gam\", formula = y~x, \n              method.args = list(family = \"binomial\")) + \n  geom_abline(linetype = \"dashed\") + \n  labs(x = \"Prediction\", y = \"Truth\") + \n  theme_bw() + \n  theme(text = element_text(size = 18))\n\ncalib_plot_models",
    "crumbs": [
      "Notebook",
      "2.1. Model sculpting and interpretation - compas"
    ]
  },
  {
    "objectID": "notebook/1_introduction.html",
    "href": "notebook/1_introduction.html",
    "title": "1. Introduction of this repository",
    "section": "",
    "text": "modsculpt package: https://github.com/Genentech/modsculpt\nOutput examples (GitHub Pages): https://genentech.github.io/modsculpt_example/",
    "crumbs": [
      "Notebook",
      "1. Introduction of this repository"
    ]
  },
  {
    "objectID": "notebook/1_introduction.html#important-links",
    "href": "notebook/1_introduction.html#important-links",
    "title": "1. Introduction of this repository",
    "section": "",
    "text": "modsculpt package: https://github.com/Genentech/modsculpt\nOutput examples (GitHub Pages): https://genentech.github.io/modsculpt_example/",
    "crumbs": [
      "Notebook",
      "1. Introduction of this repository"
    ]
  },
  {
    "objectID": "notebook/1_introduction.html#table-of-contents",
    "href": "notebook/1_introduction.html#table-of-contents",
    "title": "1. Introduction of this repository",
    "section": "Table Of Contents",
    "text": "Table Of Contents\n\nIntroduction\nOverview\n\n1. Set-up\n2. Tuning and training models\n3. Model sculpting\n4. Model evaluation\n\nDetails\n\nInstall the packages\nData examples\nModel options\nJob submission\n\nAppendix\n\nContinuous endpoint example",
    "crumbs": [
      "Notebook",
      "1. Introduction of this repository"
    ]
  },
  {
    "objectID": "notebook/1_introduction.html#introduction",
    "href": "notebook/1_introduction.html#introduction",
    "title": "1. Introduction of this repository",
    "section": "Introduction",
    "text": "Introduction\nThis repository provides a fully worked-out example of model sculpting, a method to develop interpretable, trustworthy, and high-performing additive models. The example presented here accompanies the modsculpt package, which provides a set of tools to perform model sculpting, and the slide deck (still in development) that explains the concept of model sculpting.\nHere we provide an example workflow of how to develop strong learner with hyperparameter tuning, to perform proper performance evaluation using nested cross-validation, to sculpt the strong learner into an interpretable model, and to evaluate and interpret the sculpted model.\nSimpler examples are provided in the original modsculpt repository.",
    "crumbs": [
      "Notebook",
      "1. Introduction of this repository"
    ]
  },
  {
    "objectID": "notebook/1_introduction.html#overview",
    "href": "notebook/1_introduction.html#overview",
    "title": "1. Introduction of this repository",
    "section": "Overview",
    "text": "Overview\n\n1. Set-up\n\nClone the repository\nOpen the R project file modsculpt_example.Rproj in RStudio\nInstall the necessary packages\nOpen the R script R/0_setup.R and modify the storage folder as necessary\n\nBy default it is set at output/sculpt_results folder, but you can specify any folder, including one outside of this repository (e.g. when you run this code in a cluster).\n\n\n\n\n2. Tuning and training models\n\nRun the R script R/1_prepare_data.R to prepare the example data\n\nYou can define your own data in R/define_data.R\n\nRun the R script R/2_train_models.R to train the models\n\nSee below for data examples and model options\nYou can run R/2_train_models.R interactively, or execute it in a batch mode with the command line.\nSee job submission for details\nThe following models need to be trained on the compas dataset if you want to follow the steps below\n# Note that xgb training can take some time (~1 hr on M2 MacBook Air)\nRscript R/2_train_models.R xgb compas FALSE \n# xgb_1_order is a bit faster (~30 min)\nRscript R/2_train_models.R xgb_1_order compas FALSE \n# Following models are faster (&lt;1 min)\nRscript R/2_train_models.R log_elastic compas FALSE\nRscript R/2_train_models.R log_lasso compas FALSE\nRscript R/2_train_models.R log_ridge compas FALSE\n\n[Optional] Run the R script R/2_train_models_ncv.R to perform nested cross-validation on the models\n\nThis script is necessary only if you want to perform nested cross-validation for model evaluation\nYou can run this script interactively, or execute it in a batch mode with the command line.\nSee job submission for details\n\n\n\n\n3. Model sculpting\n\nRun the R script R/3_model_sculpt_compas.R to perform model sculpting on the compas dataset\n\nYou can modify the script to evaluate the models on the bike dataset\n\n[Optional] Run the R script R/3_model_sculpt_ncv_compas.R to perform model sculpting on nested cross-validation outputs for sculpted model performance evaluation\n\n\n\n4. Model evaluation\n\nEvaluation/interpretation of sculpted models: notebooks/2_1_modsculpt_compas.qmd\nPerformance summary: notebooks/3_performance_summary.qmd\nSample outputs",
    "crumbs": [
      "Notebook",
      "1. Introduction of this repository"
    ]
  },
  {
    "objectID": "notebook/1_introduction.html#details",
    "href": "notebook/1_introduction.html#details",
    "title": "1. Introduction of this repository",
    "section": "Details",
    "text": "Details\n\nInstall the packages\nThe following packages are required to run the example in this repository.\n# Install necessary packages\ninstall_if_not_available &lt;-\n  function(pkg, from_github = FALSE, ref = NULL, min_version = NULL) {\n    \n    # Check whether it's installed and the version is ok\n    is_installed &lt;- suppressWarnings(suppressPackageStartupMessages(require(pkg, character.only = TRUE)))\n    version_ok &lt;- is.null(min_version)\n    if (is_installed & !version_ok) version_ok &lt;- packageVersion(pkg) &gt;= min_version\n    \n    # Install if necessary\n    if (!is_installed | !version_ok) {\n      if (from_github) {\n        remotes::install_github(paste0(\"Genentech/\", pkg), ref = ref)\n      } else {\n        install.packages(pkg)\n      }\n    }\n  }\n\ninstall_if_not_available(\"dplyr\")\ninstall_if_not_available(\"tidyr\")\ninstall_if_not_available(\"readr\")\ninstall_if_not_available(\"purrr\")\ninstall_if_not_available(\"lubridate\")\ninstall_if_not_available(\"here\")\ninstall_if_not_available(\"DT\")\ninstall_if_not_available(\"data.table\")\ninstall_if_not_available(\"mgcv\")\ninstall_if_not_available(\"tidymodels\")\ninstall_if_not_available(\"glmnet\")\ninstall_if_not_available(\"xgboost\")\n# devtools::install_version('xgboost', '1.7.7.1') # Version used for generating the outputs\ninstall_if_not_available(\"tune\")\ninstall_if_not_available(\"parallel\") \ninstall_if_not_available(\"doParallel\") \n\n# Install the following packages from GitHub\ninstall_if_not_available(\"remotes\")\ninstall_if_not_available(\"modsculpt\", from_github = TRUE, ref = \"v0.1.1\")\ninstall_if_not_available(\"stats4phc\", from_github = TRUE, ref = \"v0.1.1\")\n\n\nData examples\nTwo example datasets were provided, compas and bike.\n\ncompas: A dataset from the COMPAS recidivism risk assessment tool, used in the publication “Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead” by Rudin et al., available here. This is an example for binary classification.\nbike: A dataset from the Capital Bikeshare program in Washington, D.C., available here. This is an example for regression.\n\nIf you are interested in using your own data, you can define it in R/define_data.R. For binary classification task, the response variable is to be a factor with the the first level being “positive”; otherwise some of the codes make a wrong conversion.\n\n\nModel options\nThe following model_types are currently supported, made available with parsnip package. See R/define_model.R for the implementation details.\n\n\n\n\n\n\n\n\n\nmodel_type\ntask\ndescription\npackages\n\n\n\n\nxgb\nreg. or class.\nXGBoost\nxgboost\n\n\nxgb_monotone\nreg. or class.\nXGBoost with monotone constraints as defined in R/define_data.R\nxgboost\n\n\nxgb_*_order\nreg. or class.\nXGBoost with * order constraints; replace * with the number to indicate the number of your choice, e.g. xgb_1_order\nxgboost\n\n\nxgb_*_order_monotone\nreg. or class.\nXGBoost with *_order and the monotone constraints\nxgboost\n\n\nlm / logistic\nreg. / class.\nLinear model / Logistic regression\nstats / glm\n\n\nlm_elastic / log_elastic\nreg. / class.\nElastic net\nglmnet\n\n\nlm_lasso / log_lasso\nreg. / class.\nLasso\nglmnet\n\n\nlm_ridge / log_ridge\nreg. / class.\nRidge\nglmnet\n\n\nrf\nreg. or class.\nRandom forest\nranger\n\n\nlgb\nreg. or class.\nLightGBM\nbonsai, lightgbm\n\n\nrpart\nclass.\nRecursive partitioning\nrpart\n\n\nrpart_regression\nreg.\nRecursive partitioning\nrpart\n\n\n\n\n\nJob submission\nYou can run the training script R/2_train_models.R and R/2_train_models_ncv.R in a batch mode with the command line. The scripts takes three arguments: model type, dataset name, and whether to use Bayesian optimization in addition to the grid search.\nThis is particularly useful when you run the code on a cluster.\nOn you local computer, you should be able to use any terminal; on Windows PC, the terminal tab in RStudio might be the easiest.\nRscript R/2_train_models.R $1 $2 $3\nRscript R/2_train_models_ncv.R $1 $2 $3\nwhere\n\n$1 is the model type (e.g. xgb, see model options for the full list of model types)\n$2 is the dataset name (e.g. compas or bike)\n$3 is whether to use Bayesian optimization (e.g. TRUE or FALSE) in addition to the grid search\n\nBayesian optimization takes a long time to run, so it is recommended to set this to “FALSE” for an interactive run\n\n\nFor example,\nRscript R/2_train_models.R xgb compas FALSE\nRscript R/2_train_models.R lm_elastic bike FALSE",
    "crumbs": [
      "Notebook",
      "1. Introduction of this repository"
    ]
  },
  {
    "objectID": "notebook/1_introduction.html#appendix",
    "href": "notebook/1_introduction.html#appendix",
    "title": "1. Introduction of this repository",
    "section": "Appendix",
    "text": "Appendix\n\nContinuous endpoint example\nExample with bike dataset\n\nRun the R scripts R/2_train_models.R (& R/2_train_models_ncv.R) to train the models\nRscript R/2_train_models.R xgb bike FALSE \nRscript R/2_train_models.R xgb_1_order bike FALSE \nRscript R/2_train_models.R log_elastic bike FALSE\nRscript R/2_train_models.R log_lasso bike FALSE\nRscript R/2_train_models.R log_ridge bike FALSE\nRun the R script R/3_model_sculpt_bike.R (& R/3_model_sculpt_ncv_bike.R) to perform model sculpting (and nested cross-validation performance evaluation) on the bike dataset\nEvaluation/interpretation of sculpted models: notebooks/2_1_modsculpt_bike.qmd\nPerformance summary: notebooks/3_performance_summary.qmd\nSample outputs",
    "crumbs": [
      "Notebook",
      "1. Introduction of this repository"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Index",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n2024-08-29\n\n\n1. Introduction of this repository\n\n\n \n\n\n\n\n2024-09-13\n\n\n2.1. Model sculpting and interpretation - compas\n\n\n \n\n\n\n\n2024-09-05\n\n\n2.2. Model sculpting and interpretation - bike\n\n\n \n\n\n\n\n2024-09-13\n\n\n3. Performance evaluation\n\n\n \n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Index"
    ]
  },
  {
    "objectID": "index.html#important-links",
    "href": "index.html#important-links",
    "title": "Index",
    "section": "Important links",
    "text": "Important links\n\nmodsculpt package: https://github.com/Genentech/modsculpt\nGitHub repo: https://genentech.github.io/modsculpt_example/",
    "crumbs": [
      "Index"
    ]
  },
  {
    "objectID": "notebook/3_performance_summary.html",
    "href": "notebook/3_performance_summary.html",
    "title": "3. Performance evaluation",
    "section": "",
    "text": "Show the code\nlibrary(dplyr)\nlibrary(forcats)\nlibrary(stringr)\nrequireNamespace(\"DT\")\nsource(here::here(\"R\", \"0_setup.R\"))\n\ntheme_set(theme_bw(base_size = 12))\n\n\n\n\nShow the code\ndataset_to_summarize &lt;- c(\"compas\", \"bike\")\n\nseparate_sculpt_bayes &lt;- function(data) {\n  data %&gt;% \n    # parse `model` and extract `-sculpt_*`, only keep * part\n    mutate(\n      sculpt = model %&gt;% str_extract(\"-sculpt_\\\\w+$\") %&gt;% str_remove(\"-sculpt_\"),\n      sculpt = if_else(is.na(sculpt), \"orig.\", sculpt),\n      sculpt = factor(sculpt, levels = c(\"orig.\", \"rough\", \"detailed\", \"polished\")),\n      tune_bayes = if_else(str_detect(model, \"_bayes\"), TRUE, FALSE),\n      model_type = model %&gt;% str_remove(\"-sculpt_\\\\w+$\") %&gt;% str_remove(\"_bayes$\")\n    ) %&gt;%\n    relocate(model_type, tune_bayes, sculpt, .after = model)\n}",
    "crumbs": [
      "Notebook",
      "3. Performance evaluation"
    ]
  },
  {
    "objectID": "notebook/3_performance_summary.html#resampling",
    "href": "notebook/3_performance_summary.html#resampling",
    "title": "3. Performance evaluation",
    "section": "Resampling",
    "text": "Resampling\n\n\nShow the code\nres_resample %&gt;% \n  select(-model) %&gt;% \n  mutate(across(where(is.numeric), \\(x) sprintf(x, fmt = '%.4f'))) %&gt;%\n  mutate(across(where(is.character), as.factor)) %&gt;%\n  DT::datatable(filter = \"top\")",
    "crumbs": [
      "Notebook",
      "3. Performance evaluation"
    ]
  },
  {
    "objectID": "notebook/3_performance_summary.html#holdout",
    "href": "notebook/3_performance_summary.html#holdout",
    "title": "3. Performance evaluation",
    "section": "Holdout",
    "text": "Holdout\n\n\nShow the code\nres_hd %&gt;% \n  select(-model) %&gt;% \n  mutate(across(where(is.numeric), \\(x) sprintf(x, fmt = '%.4f'))) %&gt;%\n  mutate(across(where(is.character), as.factor)) %&gt;%\n  DT::datatable(filter = \"top\")",
    "crumbs": [
      "Notebook",
      "3. Performance evaluation"
    ]
  },
  {
    "objectID": "notebook/2_2_mod_sculpt_bike.html",
    "href": "notebook/2_2_mod_sculpt_bike.html",
    "title": "2.2. Model sculpting and interpretation - bike",
    "section": "",
    "text": "The following scripts need to be run first before knitting the document corresponding to model_type specified below:\n\n3_model_sculpt_bike.R",
    "crumbs": [
      "Notebook",
      "2.2. Model sculpting and interpretation - bike"
    ]
  },
  {
    "objectID": "notebook/2_2_mod_sculpt_bike.html#sculpting",
    "href": "notebook/2_2_mod_sculpt_bike.html#sculpting",
    "title": "2.2. Model sculpting and interpretation - bike",
    "section": "Sculpting",
    "text": "Sculpting\n\nMain models\n\n\nShow the code\n# load sculpted models\nrs_pm &lt;- load_results(paste0(dataset, \"-\", model_type, \"-sculpt_rough_pm.rds\"))\nds_pm &lt;- load_results(paste0(dataset, \"-\", model_type, \"-sculpt_detailed_pm.rds\"))\nps_pm &lt;- load_results(paste0(dataset, \"-\", model_type, \"-sculpt_polished_pm.rds\"))\n\n\n\n\nOther sculpting models\n\n\nShow the code\n# get rough model - on train\nrs_train &lt;- sculpt_rough(\n  dd$data$train[dd$covariates$all],\n  seed = 1234,\n  model_predict_fun = function(x) {\n    predict(xgb, new_data = x)$.pred\n  },\n  data_as_marginals = TRUE\n)\n\n# First order model\nrs_pm_xgb_fo &lt;- sculpt_rough(\n  pm, \n  seed = 1234,\n  model_predict_fun = function(x) {\n    predict(xgb_fo, new_data = x)$.pred\n  }\n)",
    "crumbs": [
      "Notebook",
      "2.2. Model sculpting and interpretation - bike"
    ]
  },
  {
    "objectID": "notebook/2_2_mod_sculpt_bike.html#ice-plots",
    "href": "notebook/2_2_mod_sculpt_bike.html#ice-plots",
    "title": "2.2. Model sculpting and interpretation - bike",
    "section": "ICE plots",
    "text": "ICE plots\n\n\nShow the code\nscale_col_update &lt;- \n  scale_color_manual(\n    values = c(\"ICE Profiles\" = \"gray60\", \"Rough model (with SE)\" = \"blue\"),\n    labels = c(\"ICE Profiles\", \"Rough model\"),\n    name = \"\"\n  )\n\nice_pm_ceteris &lt;- g_ice(rs_pm, centered = F, show_PDP = F, \n                        facet_spec = facet_specification(ncol = 3))\nice_pm &lt;- g_ice(rs_pm, centered = T, show_PDP = T, \n                facet_spec = facet_specification(ncol = 3))\n\n\n\nRoughRough: centeredRough vs direct 1st orderDetailed vs roughPolished vs rough\n\n\n\n\nShow the code\nice_pm_ceteris$continuous + theme_facets\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nice_pm_ceteris$discrete\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nice_pm$continuous + scale_col_update + theme_facets\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nice_pm$discrete + scale_col_update + theme_facets\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# comparison plot\ncomp_xgb_bayes &lt;- g_comparison(\n  sculptures = list(rs_pm, rs_pm_xgb_fo),\n  descriptions = c(\"Rough Model\", \"Direct Additive XGB\"), \n  facet_spec = facet_specification(ncol = 3)\n)\n\ncomp_xgb_bayes$continuous + theme_facets\ncomp_xgb_bayes$discrete\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# compare detailed and rough\ncomp_ds &lt;- \n  g_comparison(\n    sculptures = list(rs_pm, ds_pm),\n    descriptions = c(\"Rough Model\", \"Detailed Model\"), \n    facet_spec = facet_specification(ncol = 3)\n  )\n\ncomp_ds$continuous + theme_facets\ncomp_ds$discrete + theme_facets\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# compare detailed and rough\ncomp_ps &lt;- \n  g_comparison(\n    sculptures = list(rs_pm, ps_pm),\n    descriptions = c(\"Rough Model\", \"Polished Model\"), \n    facet_spec = facet_specification(ncol = 3)\n  )\n\ncomp_ps$continuous + theme_facets\ncomp_ps$discrete + theme_facets",
    "crumbs": [
      "Notebook",
      "2.2. Model sculpting and interpretation - bike"
    ]
  },
  {
    "objectID": "notebook/2_2_mod_sculpt_bike.html#data-density",
    "href": "notebook/2_2_mod_sculpt_bike.html#data-density",
    "title": "2.2. Model sculpting and interpretation - bike",
    "section": "Data density",
    "text": "Data density\n\n\nShow the code\ng_density_plots &lt;- g_density_ice_plot_list(ps_pm,\n                                           dd$data$train,\n                                           var_names = dd$covariates$all,\n                                           var_labels = dd$covariates$labels,\n                                           task = dd$task)\ncov_cont_ps &lt;- intersect(dd$covariates$continuous, names(ps_pm))\ncov_disc_ps &lt;- intersect(dd$covariates$discrete, names(ps_pm))\n\npatchwork::wrap_plots(g_density_plots[cov_cont_ps], ncol = 2) \npatchwork::wrap_plots(g_density_plots[cov_disc_ps], ncol = 2)",
    "crumbs": [
      "Notebook",
      "2.2. Model sculpting and interpretation - bike"
    ]
  },
  {
    "objectID": "notebook/2_2_mod_sculpt_bike.html#additivity-evaluation",
    "href": "notebook/2_2_mod_sculpt_bike.html#additivity-evaluation",
    "title": "2.2. Model sculpting and interpretation - bike",
    "section": "Additivity evaluation",
    "text": "Additivity evaluation\n\n\nShow the code\np1 &lt;- predict(xgb, new_data = pm)$.pred\np2 &lt;- predict(xgb, new_data = dd$data$train)$.pred\np3 &lt;- predict(rs_pm, pm)\np4 &lt;- predict(rs_train, dd$data$train)\n\ng_additivity(\n  sp = list(p3, p4),\n  lp = list(p1, p2),\n  descriptions = c(\"Product Marginals\", \"Train Set\")\n) + \n    labs(x = \"Rough Model Predictions\", y = \"Strong Learner Predictions\") + \n    theme_single",
    "crumbs": [
      "Notebook",
      "2.2. Model sculpting and interpretation - bike"
    ]
  },
  {
    "objectID": "notebook/2_2_mod_sculpt_bike.html#variable-importance",
    "href": "notebook/2_2_mod_sculpt_bike.html#variable-importance",
    "title": "2.2. Model sculpting and interpretation - bike",
    "section": "Variable importance",
    "text": "Variable importance\n\npmtrain\n\n\n\n\nShow the code\nvi_pm &lt;- g_var_imp(rs_pm, show_pdp_plot = FALSE, textsize = 16, var_imp_type = \"ice\")\nplot(vi_pm)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nvi_train &lt;- g_var_imp(rs_train, show_pdp_plot = FALSE, textsize = 16, var_imp_type = \"ice\")\nplot(vi_train)",
    "crumbs": [
      "Notebook",
      "2.2. Model sculpting and interpretation - bike"
    ]
  },
  {
    "objectID": "notebook/2_2_mod_sculpt_bike.html#calibration",
    "href": "notebook/2_2_mod_sculpt_bike.html#calibration",
    "title": "2.2. Model sculpting and interpretation - bike",
    "section": "Calibration",
    "text": "Calibration\n\n\nShow the code\npreds_sculptures &lt;- tibble(\n  obs = dd$data$holdout[[dd$response]],\n  xgb = predict(xgb, new_data = dd$data$holdout)$.pred,\n  rm = predict(rs_pm, newdata = dd$data$holdout),\n  pm = predict(ps_pm, newdata = dd$data$holdout),\n  dir = predict(xgb_fo, new_data = dd$data$holdout)$.pred\n) %&gt;%\n  pivot_longer(\n    cols = -obs,\n    names_to = \"Model\",\n    values_to = \"pred\"\n  ) %&gt;%\n  mutate(\n    Model = c(\n      \"xgb\" = \"XGBoost\", \"rm\" = \"Rough Model\",\n      \"pm\" = \"Polished Model\", \"dir\" = \"Direct Additive XGBoost\"\n    )[Model],\n    Model = factor(\n      Model, \n      levels = c(\n        \"XGBoost\", \"Rough Model\", \"Polished Model\", \"Direct Additive XGBoost\"\n      )\n    )\n  )\n\ncalib_plot_sculptures &lt;- ggplot(preds_sculptures) + \n  geom_smooth(aes(x = pred, y = obs, colour = Model), se = F, method = \"gam\", formula = y~x) + \n  geom_abline(linetype = \"dashed\") + \n  labs(x = \"Prediction\", y = \"Truth\") + \n  theme_bw() + \n  theme(text = element_text(size = 18))\n\ncalib_plot_sculptures",
    "crumbs": [
      "Notebook",
      "2.2. Model sculpting and interpretation - bike"
    ]
  },
  {
    "objectID": "notebook/2_2_mod_sculpt_bike.html#load-and-sculpt",
    "href": "notebook/2_2_mod_sculpt_bike.html#load-and-sculpt",
    "title": "2.2. Model sculpting and interpretation - bike",
    "section": "Load and sculpt",
    "text": "Load and sculpt\n\n\nShow the code\nelastic &lt;- load_model_if_trained(\"lm_elastic\")\nlasso &lt;- load_model_if_trained(\"lm_lasso\")\nridge &lt;- load_model_if_trained(\"lm_ridge\")\n\ndm_linm &lt;- define_model(type = \"lm\", data_info = dd)\nlinm &lt;- fit(dm_linm$workflow, data = dd$data$train)\ntg_linm &lt;- fit_resamples(dm_linm$workflow, dd$cv)\n\n\n\n\nShow the code\n# sculptures on pm from different models\nrs_pm_elastic &lt;- sculpt_rough(\n  pm,\n  seed = 1234,\n  model_predict_fun = function(x) {\n    predict(elastic, new_data = x)$.pred\n  }\n)\nrs_pm_lasso &lt;- sculpt_rough(\n  pm,\n  seed = 1234,\n  model_predict_fun = function(x) {\n    predict(lasso, new_data = x)$.pred\n  }\n)\nrs_pm_ridge &lt;- sculpt_rough(\n  pm,\n  seed = 1234,\n  model_predict_fun = function(x) {\n    predict(ridge, new_data = x)$.pred\n  }\n)\nrs_pm_linm &lt;- sculpt_rough(\n  pm,\n  seed = 1234,\n  model_predict_fun = function(x) {\n    predict(linm, new_data = x)$.pred\n  }\n)",
    "crumbs": [
      "Notebook",
      "2.2. Model sculpting and interpretation - bike"
    ]
  },
  {
    "objectID": "notebook/2_2_mod_sculpt_bike.html#ice",
    "href": "notebook/2_2_mod_sculpt_bike.html#ice",
    "title": "2.2. Model sculpting and interpretation - bike",
    "section": "ICE",
    "text": "ICE\n\n\nShow the code\ncomp_models &lt;- g_comparison(\n  sculptures = list(rs_pm_elastic, rs_pm_lasso, rs_pm_ridge, rs_pm_linm, ps_pm),\n  descriptions = c(\"Elastic Net\", \"Lasso\", \"Ridge\", \"Logistic Regression\", \"Polished\"),\n  facet_spec = facet_specification(ncol = 3)\n)\n\ncomp_models$continuous + theme_facets\ncomp_models$discrete + theme_facets",
    "crumbs": [
      "Notebook",
      "2.2. Model sculpting and interpretation - bike"
    ]
  },
  {
    "objectID": "notebook/2_2_mod_sculpt_bike.html#calibration-1",
    "href": "notebook/2_2_mod_sculpt_bike.html#calibration-1",
    "title": "2.2. Model sculpting and interpretation - bike",
    "section": "Calibration",
    "text": "Calibration\n\n\nShow the code\npreds_models &lt;- tibble(\n  obs = dd$data$holdout[[dd$response]],\n  xgbPol = predict(ps_pm, newdata = dd$data$holdout),\n  linm = predict(rs_pm_linm, newdata = dd$data$holdout),\n  elastic = predict(rs_pm_elastic, newdata = dd$data$holdout),\n  lasso = predict(rs_pm_lasso, newdata = dd$data$holdout),\n  ridge = predict(rs_pm_ridge, newdata = dd$data$holdout)\n) %&gt;% \n  pivot_longer(\n    cols = -obs,\n    names_to = \"Model\",\n    values_to = \"pred\"\n  ) %&gt;%\n  mutate(\n    Model = c(\n      \"xgbPol\" = \"Polished\", \n      \"linm\" = \"Logistic\", \"elastic\" = \"Elastic Net\", \"lasso\" = \"Lasso\", \"ridge\" = \"Ridge\" \n    )[Model]\n  )\n\n# calibration plot on holdout based on pm sculptures of different linear models\ncalib_plot_models &lt;- ggplot(preds_models) + \n  geom_smooth(aes(x = pred, y = obs, colour = Model), se = F, method = \"gam\", formula = y~x) + \n  geom_abline(linetype = \"dashed\") + \n  labs(x = \"Prediction\", y = \"Truth\") + \n  theme_bw() + \n  theme(text = element_text(size = 18))\n\ncalib_plot_models",
    "crumbs": [
      "Notebook",
      "2.2. Model sculpting and interpretation - bike"
    ]
  }
]